---
layout: page
title: Hi, I'm Gyanig
subtitle: Understanding the importance of Computer Vision &      Human Computer Interactions
use-site-title: true
---

<br> Sup, I am a computer geek interested in deep learning and projecting my work into research and academia. Recently, I started my master's studies in US. 
	Does the university really matter? I love working in research and directing my work towards impactful research topics like computer vision and human computer interactions. 
	Now, Why does it matter? My outlook on the world is a place where transformations are taking place so rapidly that its a challenge to figure out the past, 
	present and the future.<br><br> Im grateful to my mentor and professor <a href="https://cambum.net/PB/">Pradipta Biswas@IISc</a>. It is the perfect place for learning and understanding the research world. 
	I worked as research assistant for a little more over two years and Im currently looking for research problems in the domain of Object Detections, Collaborative Robotics
	and digging deep into the deep learning methodalogies. 
	<br><br>
	Life of a researcher is very different for many yet the same. I like to play a bit of guitar, click landscapes-nightsky photographs and sit in the balcony. 
	I try to keep up with the new learning methodologies like Domain Adaption, Self-Supervised, Learning, Graph Neural Networks, Inverse-Reinforcement-Learning, other novel transformer mechanisms quite often by implementing some good papers on my own.  
	<br><br>I am a part-time graduate studies teacher for mathematics 1 and 2 at PTC, Suriname. I am involved in teaching, mentoring and building learning modules for students.
	<br><br>
	

	<!-- I am 
	currently Research Assistant at <a href="https://cambum.net/I3DLab/projects.htm">Intelligent Inclusive Interaction Design (I3D) Lab, IISc Bangalore</a>
	under <a href="https://cambum.net/PB/">Prof. Pradipta Biswas</a>.<br><br><b>Ongoing:</b><br><br> My research interests are in Object Detection and Tracking, Multi-modal Learning, 
	Appearance-Based Gaze Estimation in 2D/3D, Deep Learning methodalogies and Problem Solving. Apart from the mentioned, I actively pursue 
	interests in Monocular Depth Estimation, low-computation and faster Landmark Detection library, Open-source Gaze estimation Library and Music compositions. 
	<br><br> I always dedicate my time to solving problems in the focus of Computer Vision and Human computer Interaction(+Robotics) Research.
	<br><br> I try to keep up with the basics of new learning methodologies like Domain Adaption, Self-Supervised 
	Learning, Graph Neural Networks, Inverse-Reinforcement-Learning, other novel transformer mechanisms quite often by implementing some good papers on my own.  
	<br><br>I am a part-time graduate studies teacher for mathematics 1 and 2 at PTC, Suriname. I am involved in teaching, mentoring and building learning modules for students.
	<br><br>
When I take breaks, my favourite things are to play guitar, click pictures, build small robotics stuff automating my room, basically average hobbyist guy. 
<br><br> -->


<hr style="height:2px;border-width:0;color:gray;background-color:blue">

<b>Updates not that are important:</b><br><br>

<ul>
	<li><i>October 2024:</i> Presented a presentation on Gaze Estimation with in-depth review on recent CVPR paper of "End-to-end Frame-to-gaze estimation" for class. <a href="https://drive.google.com/file/d/1CCspKUBVGH6mj887ZQ8j9TIP6-brjbum/view?usp=sharing">[Link]</a>
	</li><br>

	<li><i>October 2024:</i> Full Paper "Comparing Computer Vision Models for Low Resource Dataset to Develop a Mixed Reality based Manual Assembly Assistant"(Under Review) in prestigious ACM Conference on Intelligent User Interfaces (IUI), 2025.
	</li><br>	

	<li><i>October 2024:</i> Full Paper "A Comparative Study on Image Translation GAN Models to improve Object Detection Accuracy on Low-Resource Domains" in prestigious International Conference on Vehicular Technology and Transportation Systems (ICTTVS), 2024.
	</li><br>

	<li><i>August 2024:</i> Starting my Master's studies at University of Colorado, Boulder. 
	</li><br>

	<li><i>Febuary 2024:</i> Demo/Poster Paper "Multimodal Target Prediction for rapid Human-Robot Interaction" in prestigious 29th ACM Conference on Intelligent User Interfaces (ACM IUI) 2024.
	</li><br>

	<li><i>January 2024:</i> Paper accepted "Enhanced Human-Robot Collaboration with Intent Prediction using Deep-IRL" in prestigious IEEE International Conference on Robotics and Automation (ICRA) 2024.
	</li><br>

	<li><i>December 2023:</i> Journal accepted "Mixed Reality and Deep Learning based System for Assisting Assembly Process" available online on Springer <a href="https://link.springer.com/article/10.1007/s12193-023-00428-3">[Link]</a> 
	</li><br>
	
	<li><i>November 2023:</i> Submitted our Demo/Poster Paper "Multimodal Target Prediction for rapid Human-Robot Interaction" in prestigious 29th ACM Conference on Intelligent User Interfaces (ACM IUI) 2024.
	</li><br>

	<li><i>November 2023:</i> Submitted our Full Paper "Enhanced Human-Robot Collaboration with Intent Prediction using Deep-IRL" in prestigious IEEE International Conference on Robotics and Automation (ICRA) 2024.
	</li><br>

	<li><i>August 2023:</i> Graduated in Bachelors in Technology in Computer Science and Systems Engineering from Kalinga Institute of Industrial Technology(KIIT).
	</li><br>
	
	<li><i>March 2023:</i> Joined my first research job at I3D labs, Department of Manufacturing and Design, Indian Institute of Science as Research Assistant under Prof. Pradipta Biswas.
	</li><br>

	<li><i>December 2022:</i> Submitted for Journal "Mixed Reality and Deep Learning based System for Assisting Assembly Process" in the journal of multimedia interfaces (IF-2.9).
	</li><br>
	
	<li><i>September 2022:</i> Paper "Efficient Interaction with Automotive Heads Up Displays using Appearance-based Gaze Tracking" available online on ACM Digital library <a href="https://dl.acm.org/doi/pdf/10.1145/3544999.3554818">[Link]</a> 
	</li><br>
	
	<li><i>July 2022:</i> Paper "Efficient Interaction with Automotive Heads Up Displays using Appearance-based Gaze Tracking" accepted in Work-In-Progress Track at AutomotiveUI 2022 Conference.
	</li><br>

	<li><i>July 2022:</i> Had an oppurtunity to showcase Lab Projects on <a href="https://www.linkedin.com/posts/pradipta-biswas-5a52518_unesco-team-visited-our-lab-for-their-upcoming-activity-6950421667617591296-Y1W4?utm_source=linkedin_share&utm_medium=member_desktop_web">UNESCO visit</a> at I3D Labs, IISc Bangalore.  
	</li><br>
		
	<li><i>June 2022:</i> Submitted Work-in-progress paper in the AutoUI 2022
  </li><br>
  	
	<li><i>April 2022:</i> Started my first internship at I3D Labs, IISc Bangalore.
</li><br>

<li><i>September 2021:</i> Summer School Fellowship completed at CVIT, IIIT Hyderabad.
</li><br>

</ul>

<!-- 
	<li><i>January 2022:</i> <b>2 papers</b> accepted at <a href="https://2022.ieeeicassp.org/">IEEE ICASSP 2022</a>.
		These papers investigate multi-talker ASR with neural transducers, and adding domain knowledge for
		fine-tuning of large self-supervised models. <a href="./static/pdf/clsp_recruitment_poster.pdf">Here</a> is a
		poster describing both papers.
	</li><br>

	<li><i>Janurary 2022:</i> I participated in the Mini SCALE workshop organized by HLTCOE. I was in the
		<b>"Improving speech analytics for room audio"</b> team led by <a href="https://m-wiesner.github.io/">Matthew
			Wiesner</a>.
	</li><br>

	<li><i>June 2021:</i> <b>4 papers</b> accepted at <a href="https://www.interspeech2021.org/">INTERSPEECH 2021</a>.
		Check out publications page for more info! Also, I am attending ICASSP 2021 virtually :)
	</li><br>

	<li><i>April 2021:</i> Our JHU-GoVivace team placed <b>2nd</b> (and 1st in the Hindi-English task) in the <a
			href="https://navana-tech.github.io/IS21SS-indicASRchallenge/leaderboard.html">Indic code-switching
			challenge</a>.</li><br> -->

	<!-- <li><i>March 2021:</i> I will be interning (virtually) with <a
			href="https://www.microsoft.com/en-us/research/people/jinyli/">Dr. Jinyu Li</a> at Microsoft this summer.
	</li><br> -->

	<!-- <li><i>January 2021:</i> Our Hitachi-JHU team obtained <b>2nd best DER</b> in the <a
			href="https://sat.nist.gov/dihard3#tab_leaderboard">Third Dihard challenge</a>. We used several systems, and
		combined their outputs with a modified version of <a href="https://github.com/desh2608/dover-lap">DOVER-Lap</a>.
		Register for the workshop for more details!</li><br> -->

	<!-- <li><i>November 2020:</i> <b>4 papers</b> accepted at <a href="http://slt2020.org/">IEEE SLT 2021</a>. Check out
		publications page for more info!</li><br> -->

	<!-- <li><i>August 2020:</i> I will be a TA for <a href="https://jhu-intro-hlt.github.io/">Intro to HLT</a> in the fall.
	</li><br>

	<li><i>June 2020:</i> I am participating in <a
			href="https://www.clsp.jhu.edu/speech-recognition-and-diarization-for-unsegmented-multi-talker-recordings-with-speaker-overlaps/">JSALT
			2020</a>. I will be working on informed target speaker ASR with <a
			href="http://www.kecl.ntt.co.jp/icl/signal/member/marcd/">Marc Delcroix</a> and <a
			href="https://sites.google.com/view/shinjiwatanabe">Shinji Watanabe</a>.</li><br>

	<li><i>May 2020:</i> Our JHU submission to the <a
			href="https://chimechallenge.github.io/chime6/results.html">CHiME-6 challenge</a> obtained
		<b>second-best</b> results in Track 2 (diarization + ASR track). The system description paper is available <a
			href="https://arxiv.org/abs/2006.07898">here</a>.
	</li><br> -->

